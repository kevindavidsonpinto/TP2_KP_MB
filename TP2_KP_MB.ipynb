{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f8a2a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mkevin\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     26\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musu_individual_T123.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 27\u001b[0m excel_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name)\n\u001b[0;32m     29\u001b[0m gran_buenos_aires \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# se declara un variable que es igual de 1 - la numera que corresponde a gente que vive en Buenos Aires\u001b[39;00m\n\u001b[0;32m     30\u001b[0m region_filtered \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGION\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m gran_buenos_aires\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#1. Personas que viven en pobreza estan identificado según de una linea de pobreza. Gente arriba no vive en pobreza, y gente bajo vive en pobreza\n",
    "# La linea de pobreza se define en relacion con el costo para tener cosas necessario (un lugar para dormir, comida, salud, educación etc)\n",
    "# INDEC hizo un estudio con mas enfocus en ingresos, aunque el archivo que estoy usando contiene mucha mas estadisticas tambien\n",
    "#como donde se vive, con cuantas personas se vive, nivel de educacion etc.\n",
    "\n",
    "\n",
    "\n",
    "excel_file = 'usu_individual_T123.xlsx'\n",
    "\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "gran_buenos_aires = 1 # se declara un variable que es igual de 1 - la numera que corresponde a gente que vive en Buenos Aires\n",
    "region_filtered = df['REGION'] == gran_buenos_aires\n",
    "\n",
    "df = df[region_filtered] #nueva dataframe, que es actualizado en respecto con el filtro de region\n",
    "\n",
    "df = df[df['CH06'] >= 0] # filtro para que valores negativos no existan\n",
    "\n",
    "varon_mujer = df['CH04'].value_counts()\n",
    "#print(\"INDEX\", varon_mujer.index, \"VALUES\", varon_mujer.values)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(varon_mujer.index, varon_mujer.values) # Composición por sexo (c)\n",
    "ax.set_title(\"Numero de Varon y Mujeres\")\n",
    "ax.set_xlabel(\"Genero\")\n",
    "ax.set_ylabel(\"Cuenta\")\n",
    "ax.set_xticks(varon_mujer.index)\n",
    "ax.set_xticklabels([\"Varon\", \"Mujeres\"])\n",
    "\n",
    "#plt.show()\n",
    "# MATRIZ de CORRELACION (d)\n",
    "fig, ax = plt.subplots()\n",
    "datos = ['CH04', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'CAT_INAC', 'IPCF'] # datos selecionados para crear el matriz\n",
    "matriz_datos = df[datos]\n",
    "matriz = matriz_datos.corr()\n",
    "sns.heatmap(matriz, annot=True, cmap=\"coolwarm\", linewidths=.5, ax=ax)\n",
    "plt.tight_layout()\n",
    "#plt.show() # estaba seguro si deberíamos monstar los grafícos con plt.show o no, pero si descomentas esta linea el grafico aparecerá\n",
    "\n",
    "\n",
    "#NUMERO DE DESOCUPADOS\n",
    "desocupados = (df['ESTADO'] == 2).sum() # cuenta de desocupados\n",
    "inactivos = (df['ESTADO'] == 3).sum() # cuenta de inactivos\n",
    "print(\"NUMERO DE DESOCUPADOS \", desocupados, \"\\nNUMERO DE INACTIVOS \", inactivos)\n",
    "\n",
    "\n",
    "medio_valor = df['IPCF'].mean() # medio valor de IPCF\n",
    "#print(\"MEDIO_VALOR\", medio_valor)\n",
    "#going to use groupby and .mean or something like that for the average\n",
    "\n",
    "\n",
    "mean_values = df.groupby('ESTADO')['IPCF'].mean() # medio valor, grupado del estado\n",
    "\n",
    "\n",
    "\n",
    "filtro = mean_values.loc[[1, 2, 3]]\n",
    "filtro.index = ['Ocupado', 'Desocupado', 'Inactivo'] # Reemplazo de los nombres de el index\n",
    "print(filtro)\n",
    "\n",
    "# PARTE F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "archivo = 'tabla_adulto_equiv.xlsx'\n",
    "\n",
    "df1 = pd.read_excel(archivo, skiprows = 4, header=0) # se lee la table adulto_equiv, para que podamos usar la clave\n",
    "df1.columns = ['CH06', 'Mujeres', 'Varones']\n",
    "df1['CH06'] = df1['CH06'].str.replace(r'\\D', '', regex=True) # evitando valores 'strings' de la columna con años\n",
    "df['CH06'] = df['CH06'].astype(int) # asegurar que los valos se reconoce como numeric\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    " # se usa numpy.select para applicar la clave de valores numericos de nuestra base de datos original\n",
    "conditions_varones = [\n",
    "    (df['CH06'] == 0) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 1) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 2) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 3) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 4) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 5) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 6) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 7) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 8) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 9) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 10) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 11) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 12) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 13) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 14) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 15) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 16) & (df['CH04'] == 1),\n",
    "    (df['CH06'] == 17) & (df['CH04'] == 1),\n",
    "    ((df['CH06'] >= 18) & (df['CH06'] <= 29) & (df['CH04'] == 1)),\n",
    "    ((df['CH06'] >= 30) & (df['CH06'] <= 45) & (df['CH04'] == 1)),\n",
    "    ((df['CH06'] >= 46) & (df['CH06'] <= 60) & (df['CH04'] == 1)),\n",
    "    ((df['CH06'] >= 61) & (df['CH06'] <= 75) & (df['CH04'] == 1)),\n",
    "    (df['CH06'] > 75) & (df['CH04'] == 1),\n",
    "] # classificación de valores según de edad y genero\n",
    "\n",
    "conditions_mujeres = [\n",
    "    (df['CH06'] == 0) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 1) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 2) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 3) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 4) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 5) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 6) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 7) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 8) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 9) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 10) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 11) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 12) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 13) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 14) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 15) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 16) & (df['CH04'] == 2),\n",
    "    (df['CH06'] == 17) & (df['CH04'] == 2),\n",
    "    ((df['CH06'] >= 18) & (df['CH06'] <= 29) & (df['CH04'] == 2)),\n",
    "    ((df['CH06'] >= 30) & (df['CH06'] <= 45) & (df['CH04'] == 2)),\n",
    "    ((df['CH06'] >= 46) & (df['CH06'] <= 60) & (df['CH04'] == 2)),\n",
    "    ((df['CH06'] >= 61) & (df['CH06'] <= 75) & (df['CH04'] == 2)),\n",
    "    (df['CH06'] > 75) & (df['CH04'] == 2),\n",
    "]\n",
    "\n",
    "# Lista de valores numericos, tirado de adulto_equiv\n",
    "choices_varones = [\n",
    "    0.35, 0.37, 0.46, 0.51, 0.55, 0.60, 0.64, 0.66, 0.68, 0.69, 0.79,\n",
    "    0.82, 0.85, 0.90, 0.96, 1.00, 1.03, 1.04, 1.02, 1.00, 1.00, 0.83, 0.74\n",
    "]\n",
    "\n",
    "choices_mujeres = [\n",
    "    0.35, 0.37, 0.46, 0.51, 0.55, 0.60, 0.64, 0.66, 0.68, 0.69, 0.70,\n",
    "    0.72, 0.74, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.67, 0.63\n",
    "]\n",
    "\n",
    "# Si no hay un match, usamos 0.0\n",
    "default_choice = 0.0\n",
    "\n",
    "# Use numpy.select with the default choice for rows not matching any conditions\n",
    "df['adulto_equiv'] = np.select(conditions_varones, choices_varones) + np.select(conditions_mujeres, choices_mujeres, default_choice)\n",
    "\n",
    "ad_equiv_hogar1 = df.groupby('CODUSU')['adulto_equiv'].sum().reset_index()\n",
    "\n",
    "# Rename the aggregated column to 'ad_equiv_hogar1'\n",
    "#ad_equiv_hogar1.rename(columns={'adulto_equiv': 'ad_equiv_hogar1'}, inplace=True)\n",
    "\n",
    "# Merge 'ad_equiv_hogar1' back into your original DataFrame\n",
    "df = df.merge(ad_equiv_hogar1, on='CODUSU', how='left') # anade ad_equiv de nuestra base de datos\n",
    "df.rename(columns={'adulto_equiv_y': 'ad_equiv_hogar1'}, inplace=True)\n",
    "df.rename(columns={'adulto_equiv_x': 'adulto_equiv'}, inplace=True) # se renombra las columnas\n",
    "\n",
    "# Calculate ad_equiv_hogar as a DataFrame\n",
    "#ad_equiv_hogar = df.groupby('CODUSU')['adulto equiv'].sum().reset_index()\n",
    "\n",
    "canasta = 57371.05 # se declara canasta\n",
    "# Filter and create the respondieron DataFrame\n",
    "respondieron = df[df['ITF'] != 0].copy()\n",
    "\n",
    "respondieron['ingreso_necesario'] = respondieron['ad_equiv_hogar1'] * canasta\n",
    "respondieron['pobre'] = (respondieron['ITF'] < respondieron['ingreso_necesario']).astype(int) # se declara la columna pobreza\n",
    "\n",
    "print(\"Numero de gente en pobreza: \", respondieron['pobre'].value_counts()[1])\n",
    "#respondieron_grouped = respondieron.groupby('CODUSU').agg({'adulto_equiv': 'sum', 'ITF': 'first'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#column_list = respondieron_grouped.columns.tolist()\n",
    "#print(column_list)\n",
    "\n",
    "#print(df[['CODUSU', 'ITF', 'ad_equiv_hogar1']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(count)\n",
    "\n",
    "\n",
    "\n",
    "df.drop(columns= ['ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR',\n",
    "                    'DECCFR', 'IDECCFR','IPCF', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH']\n",
    "        # se elimina los columnas relacionados de ingresos (NOTA IMPORTANTE: No estaba seguro donde estaba el archivo codigos eph.pdf\n",
    "        # asi que tomé valores según de los identificaron relacionado de ingresos de EPH_registro_1T2023, pero si esto no es correcto,\n",
    "        # por favor avisamé y lo cambiaré!\n",
    "                )\n",
    "\n",
    "respondieron.drop(columns=['ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR',\n",
    "                    'DECCFR', 'IDECCFR','IPCF', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH',\n",
    "                           'adulto_equiv', 'ad_equiv_hogar1',\n",
    "                           'ingreso_necesario', 'ITF'])\n",
    "\n",
    "y = respondieron['pobre'] # se identifica la columna de el target variable\n",
    "\n",
    "# Assuming 'respondieron' contains your independent variables\n",
    "X = respondieron[['CH04', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'CAT_INAC']].copy()\n",
    "# otra vez los instucciones no me queda tan claro (tal vez un resultado de mi nivel de Español),\n",
    "# pero tomé los variables que usé por el confusion matrix en el primer paso, obvio hay mas variables que pueden ser considerados\n",
    "\n",
    "X['intercept'] = 1 # declaración de intercepto\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=201) # train_test_split con test_size y semilla indicado\n",
    "\n",
    "logit_model = LogisticRegression()\n",
    "logit_model.fit(X_train, y_train)\n",
    "logit_predictions = logit_model.predict(X_test) # usa logit\n",
    "\n",
    "logit_confusion = confusion_matrix(y_test, logit_predictions)\n",
    "logit_probs = logit_model.predict_proba(X_test)[:, 1]\n",
    "fpr_logit, tpr_logit, _ = roc_curve(y_test, logit_probs)\n",
    "roc_auc_logit = roc_auc_score(y_test, logit_probs)\n",
    "logit_auc = roc_auc_score(y_test, logit_model.predict_proba(X_test)[:,1])\n",
    "logit_accuracy = accuracy_score(y_test, logit_predictions)\n",
    "print(\"La precisión del Logit: %.2f\" %logit_accuracy)\n",
    "print(f\"Matriz de Confusion:\\n{logit_confusion}\")\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # knn, con vecinos indicado\n",
    "\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_probs = knn.predict_proba(X_test)[:, 1]\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_probs)\n",
    "roc_auc_knn = roc_auc_score(y_test, knn_probs)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"La precisión del KNN: {accuracy}\") # Creo que en este caso KNN funciona mejor, porque\n",
    "# los AUC scores son mas o menos iguales, pero la differencia en precisión de KNN es mas substantivo de los otros algoritmos. Tal vez para aumentar mas el valor de precisión,\n",
    "# se puede escalar los datos.\n",
    "print(f\"Matriz de Confusion:\\n{confusion}\")\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1) #lda algoritmo aplicada (no estaba tan seguro en como eligo n_components)\n",
    "lda = lda.fit(X_train, y_train)\n",
    "X_r = lda.transform(X_train)\n",
    "y_test_pred_lda = lda.predict(X_test)\n",
    "accuracy_lda = accuracy_score(y_test, y_test_pred_lda)\n",
    "lda_probs = lda.predict_proba(X_test)[:, 1]\n",
    "fpr_lda, tpr_lda, _ = roc_curve(y_test, lda_probs)\n",
    "roc_auc_lda = roc_auc_score(y_test, lda_probs) # roc score que incluyé en los graficos por cada algorithmo\n",
    "lda_confusion = confusion_matrix(y_test, y_test_pred_lda)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Matriz de Confusion de LDA:\")\n",
    "print(lda_confusion)\n",
    "print(\"La precisión del LDA: %.2f\" %accuracy_lda)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(fpr_logit, tpr_logit, color='orange', lw=2, label=f'Logistic Regression (AUC = {roc_auc_logit:.2f})') # graficar todos de las curvas de ROC\n",
    "plt.plot(fpr_knn, tpr_knn, color='green', lw=2, label=f'K-Nearest Neighbors (AUC = {roc_auc_knn:.2f})')\n",
    "plt.plot(fpr_lda, tpr_lda, color='blue', lw=2, label=f'Linear Discriminant Analysis (AUC = {roc_auc_lda:.2f}')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Falso Positivo')\n",
    "plt.ylabel('Verdadero Positivo')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curva')\n",
    "plt.legend(loc='lower right') # grafico para comparar todos de las curvas de ROC\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "norespondieron = df[df['ITF'] == 0]['ITF'] # aca tenemos norespondieron, pero no me queda claro los instrucciónes en relacion con como hacemos classificacion con norespondieron\n",
    "# Pobre es una columna que no existe en norespondieron, porque norespondieron no tiene una columna de ITF. Si me falta algún detalle por favor avisamé,\n",
    "#porque quero hacer este parte pero no entiendo exactamente como hacemos el classificaci´´n.\n",
    "\n",
    "#6. En relacion con los variables, como ya mencioné no me queda tan claro si estoy usando las variable que supongamos a usar\n",
    "# Los variable que usé me parece applicable, pero hay mucha mas variables que pordría ser interesante para usar\n",
    "# cuando entienda que variables deberíamos usar, puedo cambiar las variables y hacer este parte con el eliminacíon de variables que no son tan relevantes.\n",
    "\n",
    "# Me gustaría revisar los partes que no entendí, por favor avísame y lo apradecería mucho\n",
    "\n",
    "#gracias otra vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93e4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
